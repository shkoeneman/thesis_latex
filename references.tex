\addtocontents{toc}{\protect\vspace{\li}}
\addcontentsline{toc}{head}{REFERENCES}
\bibliography{REFERENCES}
\begin{center}
\textbf{REFERENCES}
\end{center}
\singlespace

\phantom{a}

\phantom{a}

\rff Akaike, H. (1974),
      A new look at the statistical identification model.
     {\it IEEE Transactions on Automatic Control}
     {\bf 19}, {716--723}.

\phantom{a}

\rff Azari, R., Li, L., and Tsai, C.L. (2006),
      Longitudinal data model selection.
      {\it Computational Statistics \& Data Analysis}.
      {\bf 50}, {3053--3066}.

\phantom{a}

\rff Breusch, T.S. and Pagan, A.R. (1989),
      A Simple Test for Heteroskedasticity and Random Coefficient Variation.
      {\it Econometrica}.
      {\bf 47}, {1287--1294}.

\phantom{a}

\rff Brewer, M.J., Butler, A., and Cooksley, S.L. (2016),
      The relative performance of AIC, AICC and BIC in the presence of unobserved heterogeneity.
      {\it Methods in Ecology and Evolution}.
      {\bf 7}, {679--692}.

\phantom{a}

\rff Burnham, K.P. and Anderson, D.R. (2003),
      Model Selection and Multimodel Inference: A Practical Information-Theoretic Approach.
      {\it Springer}.

\phantom{a}

\rff Cavanaugh, J.E. and Neath, A.A. (2019),
      The Akaike information criterion: Background, derivation, properties, application, interpretation, and refinements.
      {\it WIREs Comput Stat}.
      {\bf 11}, {e1460}.

\phantom{a}

\rff Hurvich, C.M. and Tsai, C.L. (1989),
      Regression and time series model selection in small samples.
      {\it Biometrika}.
      {\bf 76}, {297--307}.

\phantom{a}

\rff Hurvich, C.M. and Tsai, C.L. (1993),
      A CORRECTED AKAIKE INFORMATION CRITERION FOR VECTOR AUTOREGRESSIVE MODEL SELECTION.
      {\it Journal of Time Series Analysis}.
      {\bf 14}, {271--279}.

\phantom{a}

\rff Hurvich, C.M. and Tsai, C.L. (1995),
      Model selection for extended quasi-likelihood models in small samples.
      {\it Biometrics}.
      {\bf 51}, {1077--1084}.

\phantom{a}

\rff Hurvich, C.M., Shumway, C., and Tsai, C.L. (1990),
      Improved estimators of Kullback–Leibler information for autoregressive model selection in small samples.
      {\it Biometrika}.
      {\bf 77}, {709--719}.

\phantom{a}

\rff Kass, R.R. and Raftery, A.E. (1995),
     Bayes Factors.
     {\it Journal of the American Statistical Association}
     {\bf 22}, {773--795}.

\phantom{a}

\rff Kullback, S. (1968),
      Information theory and statistics.
      {\it Dover}.

\phantom{a}

\rff Kullback, S. and Leibler, R.A. (1951),
     On information and sufficiency.
     {\it The Annals of Mathematical Statistics}
     {\bf 22}, {79--86}.

\phantom{a}

\rff Kutner, M.H., Nachtsheim, C.R., Neter, J., and Li, W. (2005),
      Applied Linear Statistical Models.
      {\it McGraw-Hill Irwin}.

\phantom{a}

\rff Poole, M.A. and O'Farrell, P.N. (1971),
      The Assumptions of the Linear Regression Model.
      {\it Transactions of the Institute of British Geographers}
      {\bf 52}, {145--158}.

\phantom{a}

\rff Schwarz, G.E. (1978),
      Estimating the dimension of a model.
      {\it Annals of Statistics}
      {\bf 22}, {461--464}.

\phantom{a}

\rff Sugiura, N. (1978),
      Further analysis of the data by Akaike's information criterion and the finite corrections.
      {\it Communications in Statistics - Theory and Methods}
      {\bf 7}, {13--26}.

\phantom{a}

\rff White, H. (1980),
      A Heteroskedasticity-Consistent Covariance Matrix Estimator and a Direct Test for Heteroskedasticity.
      {\it Econometrica}
      {\bf 48}, {817--838}.

\phantom{a}

\rff Wilks, S.S. (1938),
      The Large-Sample Distribution of the Likelihood Ratio for Testing Composite Hypotheses.
      {\it The Annals of Mathematical Statistics}
      {\bf 9}, {60--62}.

\phantom{a}

\rff Zhang, T. and  Cavanaugh, J.E. (2016),
      A multistage algorithm for best-subset model selection based on the Kullback–Leibler discrepancy.
      {\it Computational Statistics}
      {\bf 31}, {643--669}.